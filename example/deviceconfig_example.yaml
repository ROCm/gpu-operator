apiVersion: amd.com/v1alpha1
kind: DeviceConfig
metadata:
  # the names for the device plugin, metrics exporter and node labeler pods will be prefixed with this name
  name: gpu-operator
  # it is highly recommended to use the namespace where AMD GPU Operator is running
  namespace: kube-amd-gpu
spec:
  driver:
    # set to ture for deploying out-of-tree driver with specified ROCm version 
    # set to false to directly use inbox or pre-installed driver on worker nodes
    enable: false

    # set to true to add blacklist for the amdgpu inbox driver kernel module, required for spec.driver.enable=true
    # set to false to remove blacklist for the amdgpu inbox driver kernel module, required for spec.driver.enable=false
    # the reboot of worker node is required to apply the updated blacklist
    blacklist: false
        
    # Specify the out-of-tree driver version
    version: "6.2.2"

    # Specify driver image here
    # DO NOT include the image tag as AMD GPU Operator will automatically manage the image tag for you
    # e.g. docker.io/username/amdgpu-driver
    image: imageregistry.io/username/repo

    # Specify the credential for your private registry if it requires credential to get pull/push access
    # you can create the docker-registry type secret by running command like:
    # kubectl create secret docker-registry mysecret -n kube-amd-gpu --docker-username=xxx --docker-password=xxx
    # Make sure you created the secret within the namespace that gpu operator controller is running
    #imageRegistrySecret:
    #  name: mysecret

    # Specify the image registry TLS config if you are using insecure registry for managin driver images
    #imageRegistryTLS:
    #  insecure: true
    #  insecureSkipTLSVerify: true

    # Specify the image signing config for building + signing image within cluster
    #imageSign:
    #  keySecret:
    #    name: mysignkey
    #  certSecret:
    #    name: mysigncert

  devicePlugin:
    # Specify the device plugin image
    # default value is rocm/k8s-device-plugin:latest
    devicePluginImage: rocm/k8s-device-plugin:latest

    # Specify the node labeller image
    # default value is rocm/k8s-device-plugin:labeller-latest
    nodeLabellerImage: rocm/k8s-device-plugin:labeller-latest

    # Specify to enable/disable the node labeller
    # node labeller is required for adding / removing blacklist config of amdgpu kernel module
    # please set to true if you want to blacklist the inbox driver and use our-of-tree driver
    enableNodeLabeller: true
        
  # Specify the metrics exporter config
  metricsExporter:
    # To enable/disable the metrics exporter, disabled by default
    enable: true

    # configure a node selector for metrics exporter
    # if not specified metrics exporter will use the node selector from spec.selector by default
    #selector:
    #  feature.node.kubernetes.io/amd-gpu: "true"

    # kubernetes service type for metrics exporter, clusterIP(default) or NodePort
    serviceType: "NodePort"

    # internal service port used for in-cluster and node access to pull metrics from the metrics-exporter (default 5000)
    port: 5000

    # Node port for metrics exporter service, metrics endpoint $node-ip:$nodePort
    nodePort: 32500

    # exporter image
    image: docker.io/rocm/device-metrics-exporter:v1.2.0

    # image pull secrets for fetching metrics exporter image
    #imageRegistrySecret:
    #  name: exporterimagesecret

    # metrics config in configmap
    config:
      # configmap name, example config in example/metricsExporter/config.json
      name: configmap-name

  # Specify the testrunner config
  testRunner:
    # To enable/disable the testrunner, disabled by default
    enable: True

    # testrunner image
    image: docker.io/rocm/test-runner:v1.2.0-beta.0

    # image pull policy for the testrunner
    # default value is IfNotPresent for valid tags, Always for no tag or "latest" tag
    imagePullPolicy: "Always"

    # specify the mount for test logs
    logsLocation:
      # mount path inside test runner container
      mountPath: "/var/log/amd-test-runner"

      # host path to be mounted into test runner container
      hostPath: "/var/log/amd-test-runner"

  # Specifythe node to be managed by this DeviceConfig Custom Resource
  selector:
    feature.node.kubernetes.io/amd-gpu: "true"
